This folder contains all the files required for Reinforcement Learning Programming Assignment 2. The project includes implementation of GridWorld environments, SARSA and Q-learning algorithms, hyperparameter tuning, evaluation over multiple seeds, and generation of all the plots used in the report.

Folder Description

[RL_PA_2]
 ├── RL_Assignment.py
 ├── env.py
 ├── grid_world.py
 ├── best_hyperparams.json
 ├── readme.txt
 │
 ├── [results]
 │     ├── reward plots
 │     ├── step plots
 │     ├── heatmaps
 │     └── evaluation_summary.json
 │
 ├── [venv]
 │     ├── Scripts
 │     ├── Lib
 │     └── other environment files
 │
 └── [__pycache__]


-RL_PA_2.py
This is the main script for the assignment. It runs all tasks including Task 1, Task 2A, Task 2B, and the extra heatmap metrics. It contains the implementation of SARSA, Q-learning, hyperparameter tuning for all 20 configurations, evaluation across seeds, and saving the results.

-env.py
This file defines the two environment setups used in the assignment.
create_standard_grid() creates the 10x10 standard GridWorld.
create_four_room() creates the four-room environment with the optional goal switching behaviour.

-grid_world.py
This file implements the GridWorld class used by both environments. It manages transitions, wind effect, bad states, restart states, and reward structure. It also defines reset and step functions that control the agent's interaction with the environment.

-best_hyperparams.json
This file stores the final hyperparameters for all configurations after Task 2A tuning. These values are used in Task 2B for evaluation.

-results folder
All the plots generated by the program are saved here. This includes reward curves, steps per episode, state visit heatmaps, and Q-value heatmaps for every configuration.

-venv folder
Contains the Python virtual environment created for this project. This folder is optional for evaluation but included for completeness.



- Instructions to Run

Open the terminal inside the RL_PA_2 folder.

(Optional) Activate the virtual environment using
venv\Scripts\activate

Install required dependencies using
pip install numpy matplotlib

Run the project using
python RL_Assignment.py

All experiment results will appear inside the results folder automatically.

Notes

The code follows the structure given in the assignment instructions.
Hyperparameter tuning uses a grid search over alpha, gamma, and exploration parameters.
Final evaluation is done over multiple seeds as required.
All graphs used in the final report are stored inside the results folder.